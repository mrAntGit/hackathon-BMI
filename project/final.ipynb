{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df1c5bc-d1fe-45d6-b1cb-1b09e796dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ipywidgets import *\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5245e9b0-7e33-4e08-b0f2-4fb6bf377cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.path.join(os.getcwd(), '..', 'datasets', 'co_feats32.pkl')\n",
    "\n",
    "with open(datapath, 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc09f671-1e51-4b1d-a428-02fe96b360fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"prototype, not really based in any sound logic just wanted to throw something at the wall\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba84a859-54c3-46c8-a4b1-4c13dec39102",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "\n",
    "def load_dataset(path):\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext == \".pkl\":\n",
    "        with open(path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    elif ext == \".npz\":\n",
    "        return dict(np.load(path, allow_pickle=True))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file: {path}\")\n",
    "\n",
    "# look up spiking freq in actual paper to fill in \n",
    "def compute_sbp(neural, fs=1000 / 3.5, band=(300, 6000)):\n",
    "    freqs, psd = welch(neural, fs=fs, nperseg=min(neural.shape[0], int(fs)), axis=0)\n",
    "    band_mask = (freqs >= band[0]) & (freqs <= band[1])\n",
    "    sbp = np.trapz(psd[band_mask, :], freqs[band_mask], axis=0)\n",
    "    return sbp\n",
    "    \n",
    "def rank_datasets_by_mean_sbp(folder, fs=30000, band=(300, 6000), top_k_channels=10):\n",
    "    results = []\n",
    "    for fname in sorted(os.listdir(folder)):\n",
    "        if not fname.lower().endswith((\".pkl\", \".npz\")):\n",
    "            continue\n",
    "        path = os.path.join(folder, fname)\n",
    "        try:\n",
    "            data = load_dataset(path)\n",
    "            if \"neural\" not in data:\n",
    "                continue\n",
    "            neural = np.asarray(data[\"neural\"])\n",
    "            sbp = compute_sbp(neural, fs=fs, band=band)\n",
    "            mean_sbp = float(np.mean(sbp))\n",
    "            top_channels = np.argsort(sbp)[::-1][:top_k_channels]\n",
    "            results.append({\n",
    "                \"path\": path,\n",
    "                \"mean_sbp\": mean_sbp,\n",
    "                \"top_channels_idx\": top_channels.tolist(),\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] Skipping {path}: {e}\")\n",
    "    results.sort(key=lambda x: x[\"mean_sbp\"], reverse=True)\n",
    "    return results\n",
    "\n",
    "def summarize(results, max_rows=10):\n",
    "    print(f\"\\nDatasets ranked by mean SBP (top {min(max_rows, len(results))}):\\n\")\n",
    "    for i, r in enumerate(results[:max_rows], 1):\n",
    "        print(f\"{i:2d}. {os.path.basename(r['path'])} | mean SBP: {r['mean_sbp']:.3e} | top channels: {r['top_channels_idx'][:5]}...\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    folder = \"/home/efri-student22/hackathon-BMI/datasets\"\n",
    "    results = rank_datasets_by_mean_sbp(folder, fs=30000, band=(300, 1000))\n",
    "    summarize(results)\n",
    "\n",
    "    if results:\n",
    "        best = results[0]\n",
    "        print(\"\\nSBP datasets by mean:\")\n",
    "        print(\" Mean SBP:\", best[\"mean_sbp\"])\n",
    "        print(\" Top channel:\", best[\"top_channels_idx\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca417b6-cfe2-4e11-8fd6-b69b2a007e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Channel exclusion, this was done using our comparison to mean velocity and (explain with disertation in notes), working rand pile {58, 94, 31, 65,}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6598e49-cc52-4c16-affd-d2eff08f0136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding in exclusion\n",
    "exclude = {31, 11, 69, 1, 62, 94, 65, 58, 51, 30}\n",
    "C_all = data['neural'].shape[1]\n",
    "keep_idx = [ch for ch in range(C_all) if ch not in exclude]\n",
    "\n",
    "neu = data['neural'][:, keep_idx]\n",
    "vel = data['behavior'][:, [2, 3]]\n",
    "\n",
    "hist = 6\n",
    "T, C = neu.shape\n",
    "\n",
    "adjneu = np.zeros((T - hist, C, hist + 1))\n",
    "for h in range(hist + 1):\n",
    "    adjneu[:, :, h] = neu[h:T - hist + h, :]\n",
    "\n",
    "adjneu = adjneu.reshape(T - hist, C * (hist + 1))\n",
    "adjvel = vel[hist:, :]\n",
    "\n",
    "print(f\"Excluded {C_all - C} channels → kept {C}\")\n",
    "assert adjneu.shape[0] == adjvel.shape[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(adjneu, adjvel, test_size=0.2, shuffle=False)\n",
    "\n",
    "ridge = Ridge(alpha=0.001)\n",
    "ridge.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8219b0d-9e2e-4903-9c38-b2585012ed2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13a018f-6b80-4181-9ba4-224db419791d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dd3667-e8de-4fac-93c2-9b3ef1ea8504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the ridge regression\n",
    "yhat = ridge.predict(X_test)\n",
    "\n",
    "# show test r^2\n",
    "print(f'Test R2: {ridge.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b7a9a-8b06-4fe5-8340-3c1125fc050d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted vs. true kinematics\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (9, 4))\n",
    "finger = ['IDX','MRP']\n",
    "for i in range(2):\n",
    "    ax[i].plot(y_test[0:100,i], c='k')\n",
    "    ax[i].plot(yhat[0:100,i], c='r')\n",
    "    ax[i].set(xlim=(0,100),title=f'{finger[i]} velocity (%flex/bin)')\n",
    "    if i == 0:\n",
    "        ax[i].legend(('True', 'Predicted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736a6470-115e-4162-b643-f47bf4b808e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"pearson corrilation, method to madness\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49020d2-17ca-41a1-b1c3-e73e72e45302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54bdb3f-6251-429b-830b-c6c1bae00feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# import os\n",
    "# import pandas as pd\n",
    "# pd.set_option('display.max_row', None)\n",
    "# from scipy import stats\n",
    "# import numpy as np\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "# %matplotlib inline\n",
    "# from ipywidgets import *\n",
    "\n",
    "# from sklearn.linear_model import Ridge\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.decomposition import PCA\n",
    "\n",
    "# datapath = os.path.join(os.getcwd(), '..', 'datasets', 'co_feats32.pkl')\n",
    "\n",
    "# with open(datapath, 'rb') as f:\n",
    "#     data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dee0cf3-de14-4773-8db7-f74eb9797739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract neural (SBP) and velocity data\n",
    "neu = data['neural']  # Nx96 array\n",
    "vel = data['behavior'][:, [2, 3]]  # Nx2 array (IDX_velocity, MRP_velocity)\n",
    "\n",
    "print(f\"Neural data shape: {neu.shape}\")\n",
    "print(f\"Velocity data shape: {vel.shape}\")\n",
    "\n",
    "# Calculate median velocity for splitting\n",
    "vel_combined = np.linalg.norm(vel, axis=1)  # Combined velocity magnitude\n",
    "median_vel = np.median(vel_combined)\n",
    "\n",
    "print(f\"\\nMedian velocity: {median_vel:.4f}\")\n",
    "\n",
    "# Split data into high and low velocity groups\n",
    "high_vel_mask = vel_combined >= median_vel\n",
    "low_vel_mask = vel_combined < median_vel\n",
    "\n",
    "# Group neural data by velocity condition\n",
    "grouped = {'neural': [], 'behavior': []}\n",
    "grouped['neural'].append(neu[high_vel_mask])  # High velocity group\n",
    "grouped['neural'].append(neu[low_vel_mask])   # Low velocity group\n",
    "grouped['behavior'].append(vel[high_vel_mask])\n",
    "grouped['behavior'].append(vel[low_vel_mask])\n",
    "\n",
    "print(f\"High velocity samples: {grouped['neural'][0].shape[0]}\")\n",
    "print(f\"Low velocity samples: {grouped['neural'][1].shape[0]}\")\n",
    "\n",
    "# Calculate mean neural activity for each group and channel\n",
    "mean_neural_high = np.mean(grouped['neural'][0], axis=0)  # 96 channels\n",
    "mean_neural_low = np.mean(grouped['neural'][1], axis=0)   # 96 channels\n",
    "\n",
    "print(f\"\\nMean neural high shape: {mean_neural_high.shape}\")\n",
    "print(f\"Mean neural low shape: {mean_neural_low.shape}\")\n",
    "\n",
    "# Get velocity values for each group\n",
    "vel_high = vel_combined[high_vel_mask]\n",
    "vel_low = vel_combined[low_vel_mask]\n",
    "\n",
    "# Run correlations for each channel\n",
    "results = []\n",
    "\n",
    "for channel in range(neu.shape[1]):\n",
    "    # Get neural data for this channel in high and low velocity conditions\n",
    "    high_vel_neural = grouped['neural'][0][:, channel]\n",
    "    low_vel_neural = grouped['neural'][1][:, channel]\n",
    "    \n",
    "    # Correlate neural activity with velocity within high velocity group\n",
    "    pearson_r_high, pearson_p_high = stats.pearsonr(high_vel_neural, vel_high)\n",
    "    spearman_r_high, spearman_p_high = stats.spearmanr(high_vel_neural, vel_high)\n",
    "    \n",
    "    # Correlate neural activity with velocity within low velocity group\n",
    "    pearson_r_low, pearson_p_low = stats.pearsonr(low_vel_neural, vel_low)\n",
    "    spearman_r_low, spearman_p_low = stats.spearmanr(low_vel_neural, vel_low)\n",
    "    \n",
    "    # Overall correlation (across both groups)\n",
    "    all_neural = np.concatenate([high_vel_neural, low_vel_neural])\n",
    "    all_vel = np.concatenate([vel_high, vel_low])\n",
    "    pearson_r_all, pearson_p_all = stats.pearsonr(all_neural, all_vel)\n",
    "    spearman_r_all, spearman_p_all = stats.spearmanr(all_neural, all_vel)\n",
    "    \n",
    "    results.append({\n",
    "        'SBP_Channel': channel,\n",
    "        'mean_high_vel': mean_neural_high[channel],\n",
    "        'mean_low_vel': mean_neural_low[channel],\n",
    "        'mean_diff': mean_neural_high[channel] - mean_neural_low[channel],\n",
    "        'pearson_r_overall': pearson_r_all,\n",
    "        'pearson_p_overall': pearson_p_all,\n",
    "        'spearman_r_overall': spearman_r_all,\n",
    "        'spearman_p_overall': spearman_p_all,\n",
    "        'pearson_r_high': pearson_r_high,\n",
    "        'pearson_p_high': pearson_p_high,\n",
    "        'pearson_r_low': pearson_r_low,\n",
    "        'pearson_p_low': pearson_p_low,\n",
    "        'spearman_r_high': spearman_r_high,\n",
    "        'spearman_p_high': spearman_p_high,\n",
    "        'spearman_r_low': spearman_r_low,\n",
    "        'spearman_p_low': spearman_p_low,\n",
    "        'pearson_sig_005': pearson_p_all < 0.05,\n",
    "        'pearson_sig_001': pearson_p_all < 0.01\n",
    "    })\n",
    "\n",
    "# Create DataFrame with results\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Add absolute correlation columns for ranking\n",
    "results_df['pearson_r_overall_abs'] = np.abs(results_df['pearson_r_overall'])\n",
    "results_df['spearman_r_overall_abs'] = np.abs(results_df['spearman_r_overall'])\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n=== Summary Statistics ===\")\n",
    "print(f\"Total channels tested: {len(results_df)}\")\n",
    "print(f\"Significant overall correlation at p<0.05: {results_df['pearson_sig_005'].sum()}\")\n",
    "print(f\"Significant overall correlation at p<0.01: {results_df['pearson_sig_001'].sum()}\")\n",
    "\n",
    "# Rank all channels by correlation magnitude (absolute value)\n",
    "results_df_sorted = results_df.sort_values('pearson_r_overall_abs', ascending=False)\n",
    "print(\"\\n=== All Channels Ranked by Correlation Magnitude (Overall Pearson) ===\")\n",
    "print(results_df_sorted[['SBP_Channel', 'pearson_r_overall', 'pearson_r_overall_abs', 'pearson_p_overall']])\n",
    "\n",
    "print(\"\\n=== Analysis Complete ===\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec2858-bce5-40b8-b3a4-ea95820522dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"putting it all together\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ed7dba-0c5c-4624-b6a8-200388b0195e",
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = channels = {\n",
    "    42, 85, 12, 77,\n",
    "    56, 5, 93, 38, 16,\n",
    "    4, 7, 24, 40, 57,\n",
    "    46, 49, 52, 61, 9,\n",
    "    45, 87, 47, 22, 18,\n",
    "    59, 48, 83, 88, 26,\n",
    "    81, 63, 15, 35, 28,\n",
    "    27, 19, 43, 55, 13,\n",
    "    41, 33, 29, 95, 20,\n",
    "    53, 71, 25, 92, 44,\n",
    "    54, 21, 60, 76, 23,\n",
    "    17, 30, 51, 58, 65,\n",
    "    94, 62, 1, 69, 11,\n",
    "    31\n",
    "}\n",
    "\n",
    "# fixed a bug caused by hard-coding 96 neural channels\n",
    "# by dynamically reading the actual number of channels (C = neu.shape[1]), \n",
    "# code now adapts automatically, and correctly builds the decoder using only the selected channels\n",
    "C_all = data['neural'].shape[1]\n",
    "keep_idx = [ch for ch in range(C_all) if ch not in exclude]\n",
    "\n",
    "neu = data['neural'][:, keep_idx]\n",
    "vel = data['behavior'][:, [2, 3]]\n",
    "\n",
    "hist = 6\n",
    "T, C = neu.shape\n",
    "\n",
    "adjneu = np.zeros((T - hist, C, hist + 1))\n",
    "for h in range(hist + 1):\n",
    "    adjneu[:, :, h] = neu[h:T - hist + h, :]\n",
    "\n",
    "adjneu = adjneu.reshape(T - hist, C * (hist + 1))\n",
    "adjvel = vel[hist:, :]\n",
    "\n",
    "print(f\"Excluded {C_all - C} channels → kept {C}\")\n",
    "assert adjneu.shape[0] == adjvel.shape[0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(adjneu, adjvel, test_size=0.2, shuffle=False)\n",
    "\n",
    "ridge = Ridge(alpha=0.001)\n",
    "ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f028b4-77c9-4850-8eb7-74ee61cb4404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the ridge regression\n",
    "yhat = ridge.predict(X_test)\n",
    "\n",
    "# show test r^2\n",
    "print(f'Test R2: {ridge.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad98028-9031-4195-801a-41a910fbb480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot predicted vs. true kinematics\n",
    "\n",
    "fig, ax = plt.subplots(1,2, figsize = (9, 4))\n",
    "finger = ['IDX','MRP']\n",
    "for i in range(2):\n",
    "    ax[i].plot(y_test[0:100,i], c='k')\n",
    "    ax[i].plot(yhat[0:100,i], c='r')\n",
    "    ax[i].set(xlim=(0,100),title=f'{finger[i]} velocity (%flex/bin)')\n",
    "    if i == 0:\n",
    "        ax[i].legend(('True', 'Predicted'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
